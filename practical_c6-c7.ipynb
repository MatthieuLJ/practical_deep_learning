{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51b04557",
   "metadata": {},
   "source": [
    "## Nearest Centroid\n",
    "\n",
    "Train: Calculate the centroids for the samples of each label\n",
    "Run: Find which centroid is the closest\n",
    "\n",
    "## k-NN classifier\n",
    "\n",
    "Train: Nothing\n",
    "Run: Look at the nearest neighbors from the training set\n",
    "\n",
    "## Naive Bayes classifier\n",
    "\n",
    "Train: For each category and for the whole set of samples, we build\n",
    "distributions for each component (we assume those are independent from each\n",
    "others) so that we can later calculate the probability of a component to be a\n",
    "certain value knowing what category it may belong to.\n",
    "Run: For each possible category, we calculate the probability of a sample\n",
    "with components $x_i$ being a particular category $y$ by calculating:\n",
    "\n",
    "$P(y | x_i) = \\cfrac {\\prod_i P(x_i | y) \\times P(y)}{P(x_i)}$\n",
    "\n",
    "## Decision tree classifier\n",
    "\n",
    "Train: Given the training set, we build a decision tree. At each node, find the\n",
    "component that best separate two groups through brute force, using the Gini\n",
    "index. Use binning for continuous data.\n",
    "Run: Walk through the tree.\n",
    "\n",
    "## Random forest classifier\n",
    "\n",
    "Train: Generate multiple decision tree. For each of them, select a subset of the\n",
    "features and generate a different training set (allowing duplicates of samples).\n",
    "Run: Walk through the trees and using voting between them.\n",
    "\n",
    "## SVM\n",
    "\n",
    "Train: Create a maximum margin separation between the samples. Basic case is\n",
    "linear, but can be changed using kernels.\n",
    "Run: See on what side of the hyperplane the new sample is\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b959221",
   "metadata": {},
   "source": [
    "# Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49da6bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def run(x_train, y_train, x_test, y_test, clf):\n",
    "    clf.fit(x_train, y_train)\n",
    "    print(\" predictions  : \", clf.predict(x_test))\n",
    "    print(\" actual labels: \", y_test)\n",
    "    print(\" score        : %0.4f\" % clf.score(x_test, y_test))\n",
    "    print()\n",
    "\n",
    "def main():\n",
    "    x = np.load(\"iris/iris_features.npy\")\n",
    "    y = np.load(\"iris/iris_labels.npy\")\n",
    "    N = 120\n",
    "    x_train = x[:N]\n",
    "    x_test = x[N:]\n",
    "    y_train = y[:N]\n",
    "    y_test = y[N:]\n",
    "    xa_train = np.load(\"iris/iris_train_features_augmented.npy\")\n",
    "    ya_train = np.load(\"iris/iris_train_labels_augmented.npy\")\n",
    "    xa_test =np.load(\"iris/iris_test_features_augmented.npy\")\n",
    "    ya_test =np.load(\"iris/iris_test_labels_augmented.npy\")\n",
    "\n",
    "    print(\"Nearest centroid:\")\n",
    "    run(x_train, y_train, x_test, y_test, NearestCentroid())\n",
    "    print(\"k-NN classifier (k=3):\")\n",
    "    run(x_train, y_train, x_test, y_test, KNeighborsClassifier(n_neighbors=3))\n",
    "    print(\"Naive Bayes classifier (Gaussian):\")\n",
    "    run(x_train, y_train, x_test, y_test, GaussianNB())\n",
    "    print(\"Naive Bayes classifier (Multinomial):\")\n",
    "    run(x_train, y_train, x_test, y_test, MultinomialNB())\n",
    "    print(\"Decision Tree classifier:\")\n",
    "    run(x_train, y_train, x_test, y_test, DecisionTreeClassifier())\n",
    "    print(\"Random Forest classifier (estimators=5):\")\n",
    "    run(xa_train, ya_train, xa_test, ya_test, RandomForestClassifier(n_estimators=5))\n",
    "\n",
    "    print(\"SVM (linear, C=1.0):\")\n",
    "    run(xa_train, ya_train, xa_test, ya_test, SVC(kernel=\"linear\", C=1.0))\n",
    "    print(\"SVM (RBF, C=1.0, gamma=0.25):\")\n",
    "    run(xa_train, ya_train, xa_test, ya_test, SVC(kernel=\"rbf\", C=1.0, gamma=0.25))\n",
    "    print(\"SVM (RBF, C=1.0, gamma=0.001, augmented)\")\n",
    "    run(xa_train, ya_train, xa_test, ya_test, SVC(kernel=\"rbf\", C=1.0, gamma=0.001))\n",
    "    print(\"SVM (RBF, C=1.0, gamma=0.001, original)\")\n",
    "    run(x_train, y_train, x_test, y_test, SVC(kernel=\"rbf\", C=1.0, gamma=0.001))\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29dfb8ce",
   "metadata": {},
   "source": [
    "# Breast Cancer dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3389b948",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def run(x_train, y_train, x_test, y_test, clf):\n",
    "    clf.fit(x_train, y_train)\n",
    "    print(\"    score = %0.4f\" % clf.score(x_test, y_test))\n",
    "    print()\n",
    "\n",
    "def main():\n",
    "    x = np.load(\"breast/bc_features_standard.npy\")\n",
    "    y = np.load(\"breast/bc_labels.npy\")\n",
    "    N = 455\n",
    "    x_train = x[:N];  x_test = x[N:]\n",
    "    y_train = y[:N];  y_test = y[N:]\n",
    "\n",
    "    print(\"Nearest centroid:\")\n",
    "    run(x_train, y_train, x_test, y_test, NearestCentroid())\n",
    "    print(\"k-NN classifier (k=3):\")\n",
    "    run(x_train, y_train, x_test, y_test, KNeighborsClassifier(n_neighbors=3))\n",
    "    print(\"k-NN classifier (k=7):\")\n",
    "    run(x_train, y_train, x_test, y_test, KNeighborsClassifier(n_neighbors=7))\n",
    "    print(\"Naive Bayes classifier (Gaussian):\")\n",
    "    run(x_train, y_train, x_test, y_test, GaussianNB())\n",
    "    print(\"Decision Tree classifier:\")\n",
    "    run(x_train, y_train, x_test, y_test, DecisionTreeClassifier())\n",
    "    print(\"Random Forest classifier (estimators=5):\")\n",
    "    run(x_train, y_train, x_test, y_test, RandomForestClassifier(n_estimators=5))\n",
    "    print(\"Random Forest classifier (estimators=50):\")\n",
    "    run(x_train, y_train, x_test, y_test, RandomForestClassifier(n_estimators=50))\n",
    "    print(\"SVM (linear, C=1.0):\")\n",
    "    run(x_train, y_train, x_test, y_test, SVC(kernel=\"linear\", C=1.0))\n",
    "    print(\"SVM (RBF, C=1.0, gamma=0.03333):\")\n",
    "    run(x_train, y_train, x_test, y_test, SVC(kernel=\"rbf\", C=1.0, gamma=0.03333))\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f1cf91",
   "metadata": {},
   "source": [
    "Using k-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed22ce8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import sys\n",
    "\n",
    "def run(x_train, y_train, x_test, y_test, clf):\n",
    "    clf.fit(x_train, y_train)\n",
    "    return clf.score(x_test, y_test)\n",
    "\n",
    "def split(x,y,k,m):\n",
    "    ns = int(y.shape[0]/m)\n",
    "    s = []\n",
    "    for i in range(m):\n",
    "    \ts.append([x[(ns*i):(ns*i+ns)],\n",
    "                  y[(ns*i):(ns*i+ns)]])\n",
    "    x_test, y_test = s[k]\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    for i in range(m):\n",
    "        if (i==k):\n",
    "            continue\n",
    "        else:\n",
    "            a,b = s[i]\n",
    "            x_train.append(a)\n",
    "            y_train.append(b)\n",
    "    x_train = np.array(x_train).reshape(((m-1)*ns,30))\n",
    "    y_train = np.array(y_train).reshape((m-1)*ns)\n",
    "    return [x_train, y_train, x_test, y_test]\n",
    "\n",
    "def pp(z,k,s):\n",
    "    m = z.shape[1]\n",
    "    print(\"%-19s: %0.4f +/- %0.4f | \" % (s, z[k].mean(), z[k].std()/np.sqrt(m)), end='')\n",
    "    for i in range(m):\n",
    "        print(\"%0.4f \" % z[k,i], end='')\n",
    "    print()\n",
    "\n",
    "def main():\n",
    "    x = np.load(\"breast/bc_features_standard.npy\")\n",
    "    y = np.load(\"breast/bc_labels.npy\")\n",
    "    idx = np.argsort(np.random.random(y.shape[0]))\n",
    "    x = x[idx]\n",
    "    y = y[idx]\n",
    "    m = 5 # <- number of folds\n",
    "    z = np.zeros((8,m))\n",
    "\n",
    "    for k in range(m):\n",
    "        x_train, y_train, x_test, y_test = split(x,y,k,m)\n",
    "        z[0,k] = run(x_train, y_train, x_test, y_test, NearestCentroid())\n",
    "        z[1,k] = run(x_train, y_train, x_test, y_test, KNeighborsClassifier(n_neighbors=3))\n",
    "        z[2,k] = run(x_train, y_train, x_test, y_test, KNeighborsClassifier(n_neighbors=7))\n",
    "        z[3,k] = run(x_train, y_train, x_test, y_test, GaussianNB())\n",
    "        z[4,k] = run(x_train, y_train, x_test, y_test, DecisionTreeClassifier())\n",
    "        z[5,k] = run(x_train, y_train, x_test, y_test, RandomForestClassifier(n_estimators=5))\n",
    "        z[6,k] = run(x_train, y_train, x_test, y_test, RandomForestClassifier(n_estimators=50))\n",
    "        z[7,k] = run(x_train, y_train, x_test, y_test, SVC(kernel=\"linear\", C=1.0))\n",
    "\n",
    "    pp(z,0,\"Nearest\")\n",
    "    pp(z,1,\"3-NN\")\n",
    "    pp(z,2,\"7-NN\")\n",
    "    pp(z,3,\"Naive Bayes\")\n",
    "    pp(z,4,\"Decision Tree\")\n",
    "    pp(z,5,\"Random Forest (5)\")\n",
    "    pp(z,6,\"Random Forest (50)\")\n",
    "    pp(z,7,\"SVM (linear)\")\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d7127c",
   "metadata": {},
   "source": [
    "# MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f31a34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models trained on raw [0,255] images:\n",
      "    Nearest centroid          : "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/djens/projects/practical_deep/.venv/lib/python3.12/site-packages/sklearn/neighbors/_nearest_centroid.py:244: UserWarning: self.within_class_std_dev_ has at least 1 zero standard deviation.Inputs within the same classes for at least 1 feature are identical.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score = 0.8203 (time, train=   0.511, test=   0.089)\n",
      "    k-NN classifier (k=3)     : score = 0.9705 (time, train=   0.021, test=   5.535)\n",
      "    k-NN classifier (k=7)     : score = 0.9694 (time, train=   0.033, test=   8.394)\n",
      "    Naive Bayes (Gaussian)    : score = 0.5558 (time, train=   0.692, test=   0.407)\n",
      "    Decision Tree             : score = 0.8784 (time, train=  15.551, test=   0.012)\n",
      "    Random Forest (trees=  5) : score = 0.9186 (time, train=   1.485, test=   0.022)\n",
      "    Random Forest (trees= 50) : score = 0.9672 (time, train=  16.359, test=   0.119)\n",
      "    Random Forest (trees=500) : score = 0.9717 (time, train= 152.042, test=   1.093)\n",
      "    Random Forest (trees=1000): score = 0.9714 (time, train= 323.391, test=   2.337)\n",
      "    LinearSVM (C=0.01)        : score = 0.9175 (time, train=1213.297, test=   0.071)\n",
      "    LinearSVM (C=0.1)         : "
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import decomposition\n",
    "\n",
    "def run(x_train, y_train, x_test, y_test, clf):\n",
    "    s = time.time()\n",
    "    clf.fit(x_train, y_train)\n",
    "    e_train = time.time() - s\n",
    "    s = time.time()\n",
    "    score = clf.score(x_test, y_test)\n",
    "    e_test = time.time() - s\n",
    "    print(\"score = %0.4f (time, train=%8.3f, test=%8.3f)\" % (score, e_train, e_test))\n",
    "\n",
    "def train(x_train, y_train, x_test, y_test):\n",
    "    print(\"    Nearest centroid          : \", end='')\n",
    "    run(x_train, y_train, x_test, y_test, NearestCentroid())\n",
    "    print(\"    k-NN classifier (k=3)     : \", end='')\n",
    "    run(x_train, y_train, x_test, y_test, KNeighborsClassifier(n_neighbors=3))\n",
    "    print(\"    k-NN classifier (k=7)     : \", end='')\n",
    "    run(x_train, y_train, x_test, y_test, KNeighborsClassifier(n_neighbors=7))\n",
    "    print(\"    Naive Bayes (Gaussian)    : \", end='')\n",
    "    run(x_train, y_train, x_test, y_test, GaussianNB())\n",
    "    print(\"    Decision Tree             : \", end='')\n",
    "    run(x_train, y_train, x_test, y_test, DecisionTreeClassifier())\n",
    "    print(\"    Random Forest (trees=  5) : \", end='')\n",
    "    run(x_train, y_train, x_test, y_test, RandomForestClassifier(n_estimators=5))\n",
    "    print(\"    Random Forest (trees= 50) : \", end='')\n",
    "    run(x_train, y_train, x_test, y_test, RandomForestClassifier(n_estimators=50))\n",
    "    print(\"    Random Forest (trees=500) : \", end='')\n",
    "    run(x_train, y_train, x_test, y_test, RandomForestClassifier(n_estimators=500))\n",
    "    print(\"    Random Forest (trees=1000): \", end='')\n",
    "    run(x_train, y_train, x_test, y_test, RandomForestClassifier(n_estimators=1000))\n",
    "    print(\"    LinearSVM (C=0.01)        : \", end='')\n",
    "    run(x_train, y_train, x_test, y_test, LinearSVC(C=0.01))\n",
    "    print(\"    LinearSVM (C=0.1)         : \", end='')\n",
    "    run(x_train, y_train, x_test, y_test, LinearSVC(C=0.1))\n",
    "    print(\"    LinearSVM (C=1.0)         : \", end='')\n",
    "    run(x_train, y_train, x_test, y_test, LinearSVC(C=1.0))\n",
    "    print(\"    LinearSVM (C=10.0)        : \", end='')\n",
    "    run(x_train, y_train, x_test, y_test, LinearSVC(C=10.0))\n",
    "\n",
    "def main():\n",
    "    x_train = np.load(\"mnist/mnist_train_vectors.npy\").astype(\"float64\")\n",
    "    y_train = np.load(\"mnist/mnist_train_labels.npy\")\n",
    "    x_test = np.load(\"mnist/mnist_test_vectors.npy\").astype(\"float64\")\n",
    "    y_test = np.load(\"mnist/mnist_test_labels.npy\")\n",
    "\n",
    "    print(\"Models trained on raw [0,255] images:\")\n",
    "    train(x_train, y_train, x_test, y_test)\n",
    "    print(\"Models trained on raw [0,1) images:\")\n",
    "    train(x_train/256.0, y_train, x_test/256.0, y_test)\n",
    "\n",
    "    m = x_train.mean(axis=0)\n",
    "    s = x_train.std(axis=0) + 1e-8\n",
    "    x_ntrain = (x_train - m) / s\n",
    "    x_ntest  = (x_test - m) / s\n",
    "\n",
    "    print(\"Models trained on normalized images:\")\n",
    "    train(x_ntrain, y_train, x_ntest, y_test)\n",
    "\n",
    "    pca = decomposition.PCA(n_components=15)\n",
    "    pca.fit(x_ntrain)\n",
    "    x_ptrain = pca.transform(x_ntrain)\n",
    "    x_ptest = pca.transform(x_ntest)\n",
    "\n",
    "    print(\"Models trained on first 15 PCA components of normalized images:\")\n",
    "    train(x_ptrain, y_train, x_ptest, y_test)\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8b0288",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import decomposition\n",
    "\n",
    "def run(x_train, y_train, x_test, y_test, clf):\n",
    "    s = time.time()\n",
    "    clf.fit(x_train, y_train)\n",
    "    e_train = time.time() - s\n",
    "    s = time.time()\n",
    "    score = clf.score(x_test, y_test)\n",
    "    e_test = time.time() - s\n",
    "    return [score, e_train, e_test]\n",
    "\n",
    "def main():\n",
    "    x_train = np.load(\"mnist/mnist_train_vectors.npy\").astype(\"float64\")\n",
    "    y_train = np.load(\"mnist/mnist_train_labels.npy\")\n",
    "    x_test = np.load(\"mnist/mnist_test_vectors.npy\").astype(\"float64\")\n",
    "    y_test = np.load(\"mnist/mnist_test_labels.npy\")\n",
    "    m = x_train.mean(axis=0)\n",
    "    s = x_train.std(axis=0) + 1e-8\n",
    "    x_ntrain = (x_train - m) / s\n",
    "    x_ntest  = (x_test - m) / s\n",
    "\n",
    "    n = 78\n",
    "    pcomp = np.linspace(10,780,n, dtype=\"int16\")\n",
    "    nb=np.zeros((n,4))\n",
    "    rf=np.zeros((n,4))\n",
    "    sv=np.zeros((n,4))\n",
    "    tv=np.zeros((n,2))\n",
    "\n",
    "    for i,p in enumerate(pcomp):\n",
    "        pca = decomposition.PCA(n_components=p)\n",
    "        pca.fit(x_ntrain)\n",
    "        xtrain = pca.transform(x_ntrain)\n",
    "        xtest = pca.transform(x_ntest)\n",
    "        tv[i,:] = [p, pca.explained_variance_ratio_.sum()]\n",
    "        sc,etrn,etst =run(xtrain, y_train, xtest, y_test, GaussianNB())\n",
    "        nb[i,:] = [p,sc,etrn,etst]\n",
    "        sc,etrn,etst =run(xtrain, y_train, xtest, y_test, RandomForestClassifier(n_estimators=50))\n",
    "        rf[i,:] = [p,sc,etrn,etst]\n",
    "        sc,etrn,etst =run(xtrain, y_train, xtest, y_test, LinearSVC(C=1.0))\n",
    "        sv[i,:] = [p,sc,etrn,etst]\n",
    "\n",
    "    np.save(\"mnist/mnist_pca_tv.npy\", tv)\n",
    "    np.save(\"mnist/mnist_pca_nb.npy\", nb)\n",
    "    np.save(\"mnist/mnist_pca_rf.npy\", rf)\n",
    "    np.save(\"mnist/mnist_pca_sv.npy\", sv)\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
